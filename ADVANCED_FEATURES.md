# ğŸš€ Chat AvanÃ§ado - DocumentaÃ§Ã£o TÃ©cnica

## ğŸ“‹ VisÃ£o Geral

O **Chat AvanÃ§ado** Ã© uma versÃ£o otimizada do sistema RAG, especialmente projetada para desenvolvedores que trabalham com documentaÃ§Ã£o tÃ©cnica. Esta versÃ£o inclui melhorias significativas em memÃ³ria, contexto e qualidade de respostas.

---

## âœ¨ Novas Features

### ğŸ§  1. MemÃ³ria Conversacional
- **O que Ã©**: O assistente agora lembra do contexto da conversa
- **BenefÃ­cio**: Perguntas de follow-up funcionam naturalmente
- **Exemplo**:
  ```
  VocÃª: "Como autenticar na API?"
  Bot: [explica autenticaÃ§Ã£o]

  VocÃª: "E se eu quiser usar OAuth?"  â† Entende que "isso" = autenticaÃ§Ã£o
  Bot: [explica OAuth no contexto da pergunta anterior]
  ```

### ğŸ“š 2. CitaÃ§Ãµes com Fontes
- **O que Ã©**: Cada resposta mostra de quais arquivos a informaÃ§Ã£o foi extraÃ­da
- **BenefÃ­cio**: Rastreabilidade e verificaÃ§Ã£o fÃ¡cil
- **Exemplo de saÃ­da**:
  ```
  ğŸ“š Fontes consultadas:
  - page_1.md
  - page_3.md
  ```

### ğŸ’» 3. Code-Aware Chunking
- **O que Ã©**: Algoritmo inteligente que preserva blocos de cÃ³digo inteiros
- **BenefÃ­cio**: Exemplos de cÃ³digo nÃ£o sÃ£o cortados no meio
- **Detalhes tÃ©cnicos**:
  - Chunk size: 1200 caracteres (vs 1000 antes)
  - Overlap: 300 caracteres (vs 200)
  - Separadores customizados para markdown e cÃ³digo

### ğŸ¯ 4. Prompt Especializado
- **O que Ã©**: Prompt otimizado para documentaÃ§Ã£o tÃ©cnica
- **CaracterÃ­sticas**:
  - âœ… PrecisÃ£o tÃ©cnica como prioridade
  - âœ… Sempre inclui exemplos de cÃ³digo quando relevante
  - âœ… Usa formataÃ§Ã£o markdown apropriada
  - âœ… Syntax highlighting automÃ¡tico
  - âœ… Contexto conversacional integrado

### âš¡ 5. Streaming de Respostas
- **O que Ã©**: Respostas aparecem em tempo real, palavra por palavra
- **BenefÃ­cio**: UX mais fluida, parece mais natural
- **ImplementaÃ§Ã£o**: `ask_question_stream()` com yield

### ğŸ” 6. Retrieval AvanÃ§ado (MMR)
- **O que Ã©**: Maximum Marginal Relevance - algoritmo que balanceia relevÃ¢ncia e diversidade
- **BenefÃ­cios**:
  - Recupera documentos relevantes MAS diversos
  - Evita recuperar 7 chunks do mesmo documento
  - Melhor cobertura da documentaÃ§Ã£o
- **ConfiguraÃ§Ã£o**:
  - k=7 documentos recuperados (vs 3 antes)
  - fetch_k=20 (busca 20, filtra para os 7 melhores)
  - lambda_mult=0.7 (70% relevÃ¢ncia, 30% diversidade)

### ğŸ›ï¸ 7. Controles de Gerenciamento
- **Limpar MemÃ³ria**: Remove histÃ³rico conversacional mantendo a coleÃ§Ã£o
- **Nova Conversa**: Limpa mensagens e memÃ³ria completamente
- **Resumo de HistÃ³rico**: Visualize Ãºltimas interaÃ§Ãµes

---

## ğŸ—ï¸ Arquitetura

### Estrutura de Arquivos
```
service/
â”œâ”€â”€ rag.py              # VersÃ£o original (simples)
â””â”€â”€ advanced_rag.py     # Nova versÃ£o avanÃ§ada â­

presentation/
â”œâ”€â”€ chat.py             # Interface simples
â””â”€â”€ advanced_chat.py    # Interface avanÃ§ada â­
```

### Fluxo de Dados

```
UsuÃ¡rio digita pergunta
       â†“
advanced_chat.py recebe input
       â†“
advanced_rag.py processa:
  1. Recupera memÃ³ria conversacional
  2. Busca documentos relevantes (MMR, k=7)
  3. Formata documentos com fontes
  4. Injeta no prompt especializado
  5. Envia para LLM (Groq)
  6. Stream da resposta
       â†“
Interface mostra resposta em tempo real
       â†“
Salva interaÃ§Ã£o na memÃ³ria
```

---

## ğŸ”§ Componentes TÃ©cnicos

### AdvancedRAGService

**Principais MÃ©todos:**

```python
# Carregar coleÃ§Ã£o de documentos
load_collection(collection_name: str) -> bool

# Fazer pergunta (modo sÃ­ncrono)
ask_question(question: str) -> str

# Fazer pergunta com streaming
ask_question_stream(question: str) -> Iterator[str]

# Buscar documentos relevantes
get_relevant_docs(question: str, k: int = 5) -> List[Dict]

# Limpar memÃ³ria
clear_memory() -> None

# Ver resumo da memÃ³ria
get_memory_summary() -> str
```

### ConfiguraÃ§Ãµes Importantes

**Embeddings:**
- Modelo: `all-MiniLM-L6-v2`
- NormalizaÃ§Ã£o: Ativada
- Device: CPU

**LLM:**
- Provider: Groq
- Modelo: `llama-3.1-8b-instant`
- Temperature: 0.1 (baixa para precisÃ£o)
- Streaming: Ativado

**MemÃ³ria:**
- Tipo: `ConversationBufferMemory`
- Limite: 2000 tokens
- Output Key: "answer"

**Text Splitter:**
- Chunk Size: 1200
- Overlap: 300
- Separadores: Customizados para cÃ³digo/markdown

**Retriever:**
- Tipo: MMR (Maximum Marginal Relevance)
- k: 7 documentos
- fetch_k: 20 candidatos
- lambda_mult: 0.7

---

## ğŸ“Š ComparaÃ§Ã£o: Simples vs AvanÃ§ado

| Feature | Chat Simples | Chat AvanÃ§ado |
|---------|--------------|---------------|
| MemÃ³ria Conversacional | âŒ NÃ£o | âœ… Sim (2000 tokens) |
| CitaÃ§Ãµes de Fontes | âŒ NÃ£o | âœ… Sim |
| Documentos Recuperados | 3 | 7 (com MMR) |
| Streaming | âŒ NÃ£o | âœ… Sim |
| Prompt | BÃ¡sico | Especializado p/ docs tÃ©cnicas |
| Chunking | PadrÃ£o (1000/200) | Code-aware (1200/300) |
| Diversidade de Docs | Simples similarity | MMR balanceado |
| Controles | SÃ³ limpar chat | Limpar memÃ³ria + chat |
| HistÃ³rico VisÃ­vel | âŒ NÃ£o | âœ… Sim |

---

## ğŸ® Como Usar

### Modo BÃ¡sico

1. **Selecione uma coleÃ§Ã£o** na barra lateral
2. Escolha **"ğŸ’¬ Chat AvanÃ§ado"** no modo
3. Aguarde carregar a documentaÃ§Ã£o
4. Digite sua pergunta e pressione Enter
5. Veja a resposta aparecer em tempo real

### Perguntas de Follow-up

```
Pergunta 1: "Como instalar a biblioteca?"
Resposta: [instruÃ§Ãµes de instalaÃ§Ã£o]

Pergunta 2: "E quais sÃ£o os requisitos?"  â† Contexto mantido!
Resposta: [requisitos, sabendo que Ã© sobre a biblioteca anterior]

Pergunta 3: "Me dÃª um exemplo bÃ¡sico"  â† Ainda no contexto!
Resposta: [exemplo de uso da biblioteca]
```

### Gerenciamento de MemÃ³ria

**Quando limpar a memÃ³ria:**
- âœ… Ao mudar de tÃ³pico completamente
- âœ… Se as respostas ficarem confusas (muito contexto)
- âœ… Ao comeÃ§ar uma nova sessÃ£o de trabalho

**Quando limpar a conversa:**
- âœ… Para comeÃ§ar do zero
- âœ… Ao trocar de coleÃ§Ã£o
- âœ… Para remover mensagens antigas da tela

---

## ğŸ’¡ Exemplos de Perguntas Ideais

### âœ… Boas Perguntas

```
"Como autenticar usando JWT nesta API?"
"Qual a diferenÃ§a entre os mÃ©todos sync e async?"
"Me mostre um exemplo de uso do hook useEffect"
"Quais parÃ¢metros a funÃ§Ã£o createUser aceita?"
"Como fazer upload de arquivos?"
"Existe rate limiting na API?"
```

### ğŸ¯ Perguntas que Aproveitam a MemÃ³ria

```
Pergunta 1: "Como criar um usuÃ¡rio?"
Pergunta 2: "E como deletar?"  â† Entende que Ã© sobre usuÃ¡rios
Pergunta 3: "Posso fazer isso em batch?"  â† Contexto mantido
Pergunta 4: "Quais sÃ£o as limitaÃ§Ãµes?"  â† Ainda no contexto
```

### ğŸ“ Perguntas Comparativas

```
"Qual a diferenÃ§a entre REST e GraphQL nesta lib?"
"Quando usar fetch vs axios aqui?"
"Comparar autenticaÃ§Ã£o por token vs session"
```

---

## ğŸ” Troubleshooting

### Respostas Fora de Contexto

**Problema**: O assistente estÃ¡ respondendo com base em conversas antigas
**SoluÃ§Ã£o**: Clique em "ğŸ§¹ Limpar MemÃ³ria" na sidebar

### Respostas Muito GenÃ©ricas

**Problema**: Respostas nÃ£o especÃ­ficas da sua documentaÃ§Ã£o
**SoluÃ§Ã£o**:
- Verifique se a coleÃ§Ã£o estÃ¡ carregada corretamente
- Tente perguntas mais especÃ­ficas
- Mencione termos-chave da sua documentaÃ§Ã£o

### Streaming Travou

**Problema**: Resposta parou no meio
**SoluÃ§Ã£o**:
- Aguarde alguns segundos (pode ser latÃªncia)
- Clique em "ğŸ—‘ï¸ Nova Conversa" e tente novamente
- Verifique sua conexÃ£o de internet

### Fontes NÃ£o Aparecem

**Problema**: Resposta sem citaÃ§Ãµes
**SoluÃ§Ã£o**: Isso Ã© normal quando a resposta vem da memÃ³ria ou quando nÃ£o hÃ¡ match nos documentos. Tente reformular a pergunta.

---

## âš™ï¸ ConfiguraÃ§Ãµes AvanÃ§adas

### Ajustar Temperatura do LLM

Edite `service/advanced_rag.py:17`:
```python
temperature=0.1  # Mais baixo = mais determinÃ­stico (0-1)
```

### Alterar NÃºmero de Documentos

Edite `service/advanced_rag.py:126-131`:
```python
search_kwargs={
    "k": 7,        # NÃºmero de documentos finais
    "fetch_k": 20, # Candidatos iniciais
}
```

### Modificar Limite de MemÃ³ria

Edite `service/advanced_rag.py:75`:
```python
max_token_limit=2000  # Tokens de histÃ³rico mantidos
```

### Customizar Prompt

Edite o prompt em `service/advanced_rag.py:147-173`

---

## ğŸ“ˆ PrÃ³ximas Melhorias (Roadmap)

### Curto Prazo
- [ ] Export de conversas para Markdown
- [ ] Pesquisa semÃ¢ntica visual (mostrar docs antes de perguntar)
- [ ] Feedback de relevÃ¢ncia (ğŸ‘ğŸ‘)
- [ ] HistÃ³rico persistente (salvar conversas)

### MÃ©dio Prazo
- [ ] Multi-query retrieval (gerar variaÃ§Ãµes da pergunta)
- [ ] Re-ranking com cross-encoder
- [ ] SugestÃµes de perguntas relacionadas
- [ ] CitaÃ§Ãµes com trechos exatos destacados

### Longo Prazo
- [ ] RAG Fusion (combinar mÃºltiplas estratÃ©gias)
- [ ] HyDE (Hypothetical Document Embeddings)
- [ ] Agente autÃ´nomo com ferramentas
- [ ] IntegraÃ§Ã£o com web search para docs externas
- [ ] SummarizaÃ§Ã£o de conversas longas

---

## ğŸ¤ Contribuindo

Ideias de melhorias? Abra uma issue ou PR!

**Ãreas de interesse:**
- Melhorias de performance
- Novos algoritmos de retrieval
- IntegraÃ§Ãµes com outras ferramentas
- UI/UX enhancements

---

## ğŸ“š ReferÃªncias

- [LangChain Documentation](https://python.langchain.com/)
- [FAISS](https://github.com/facebookresearch/faiss)
- [Groq API](https://groq.com/)
- [Streamlit](https://streamlit.io/)
- [Maximum Marginal Relevance](https://www.cs.cmu.edu/~jgc/publication/The_Use_MMR_Diversity_Based_LTMIR_1998.pdf)

---

**Desenvolvido com â¤ï¸ para desenvolvedores por desenvolvedores**
