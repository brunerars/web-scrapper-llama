import os
from langchain_community.document_loaders import DirectoryLoader, TextLoader
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_groq import ChatGroq
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableMap

class RAGService:
    def __init__(self):
        self.embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
        self.llm = ChatGroq(
            api_key=os.getenv("GROQ_API_KEY"),
            model_name="llama-3.1-8b-instant"
        )
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
        self.vectorstore = None
        self.chain = None

    def load_collection(self, collection_name):
        collection_path = f"data/collections/{collection_name}"
        # O √≠ndice FAISS ser√° salvo dentro da pr√≥pria pasta da cole√ß√£o
        faiss_index_path = os.path.join(collection_path, "faiss_index")

        # --- L√ìGICA DE CACHING ---
        # 1. VERIFICAR SE O √çNDICE J√Å EXISTE
        if os.path.exists(faiss_index_path):
            print(f"‚úÖ Carregando √≠ndice FAISS existente de: {faiss_index_path}")
            # Se existe, carrega do disco (muito r√°pido!)
            self.vectorstore = FAISS.load_local(faiss_index_path, self.embeddings, allow_dangerous_deserialization=True)
        else:
            print(f"‚ö†Ô∏è √çndice FAISS n√£o encontrado. Criando um novo para a cole√ß√£o '{collection_name}'.")
            # 2. SE N√ÉO EXISTE, FAZ O TRABALHO PESADO
            loader = DirectoryLoader(
                collection_path,
                glob="**/*.md",
                loader_cls=TextLoader,
                loader_kwargs={"encoding": "utf-8"},
            )
            documents = loader.load()
            if not documents:
                return False

            texts = self.text_splitter.split_documents(documents)
            
            # O processo lento que s√≥ roda uma vez por cole√ß√£o
            self.vectorstore = FAISS.from_documents(texts, self.embeddings)
            
            # 3. SALVA O NOVO √çNDICE EM DISCO PARA USO FUTURO
            print(f"üíæ Salvando novo √≠ndice FAISS em: {faiss_index_path}")
            self.vectorstore.save_local(faiss_index_path)
        
        # O resto do c√≥digo para criar a chain permanece o mesmo
        retriever = self.vectorstore.as_retriever(search_kwargs={"k": 3})
        prompt = ChatPromptTemplate.from_template("""
Responda baseado APENAS no contexto abaixo.
Se n√£o houver resposta nos documentos, diga que n√£o sabe.

CONTEXT:
{context}

QUESTION:
{question}
""")
        self.chain = (
            RunnableMap({
                "context": retriever,
                "question": lambda x: x,
            })
            | prompt
            | self.llm
            | StrOutputParser()
        )
        return True

    def ask_question(self, question):
        if not self.chain:
            return "Cole√ß√£o n√£o carregada."
        try:
            return self.chain.invoke(question)
        except Exception as e:
            return f"Erro ao responder: {e}"
